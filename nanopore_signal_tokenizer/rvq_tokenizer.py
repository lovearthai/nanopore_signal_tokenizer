# nanopore_signal_tokenizer/rvq_tokenizer.py

import os
import json
import gzip
import numpy as np
import torch
from multiprocessing import Process
from math import ceil
from ont_fast5_api.fast5_interface import get_fast5_file
from .nanopore import nanopore_normalize, nanopore_filter
from pathos.multiprocessing import ProcessingPool as Pool
from scipy.signal import medfilt
# train_nanopore_rvq.py
# æœ¬è„šæœ¬ç›®æ ‡ï¼šè®­ç»ƒä¸€ä¸ªè‡ªç›‘ç£æ¨¡å‹ï¼Œå°† Nanopore åŸå§‹ç”µæµä¿¡å·ï¼ˆ5kHzï¼‰è½¬æ¢ä¸ºç¦»æ•£ token åºåˆ—ï¼Œ
# ç”¨äºåç»­è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPTï¼‰å»ºæ¨¡ DNA/RNA åºåˆ—ã€‚
# æ‰€æœ‰æ³¨é‡Šå‡ä¸ºå·¥ä¸šçº§è¯¦ç»†è¯´æ˜ï¼Œé€‚åˆ PyTorch æ–°æ‰‹ç†è§£ã€‚

import os
import torch                     # PyTorch ä¸»åº“ï¼Œç”¨äºå¼ é‡è®¡ç®—å’Œæ·±åº¦å­¦ä¹ 
import torch.nn as nn            # ç¥ç»ç½‘ç»œæ¨¡å—ï¼ˆå¦‚ Conv1d, BatchNorm, SiLUï¼‰
import torch.nn.functional as F  # å‡½æ•°å¼æ¥å£ï¼ˆå¦‚ loss, paddingï¼‰
from torch.utils.data import Dataset, DataLoader  # æ•°æ®åŠ è½½å·¥å…·
import numpy as np               # æ•°å€¼è®¡ç®—ï¼ˆç”Ÿæˆæ¨¡æ‹Ÿä¿¡å·ï¼‰
from tqdm import tqdm            # è¿›åº¦æ¡æ˜¾ç¤º

# æ›¿æ¢ encodec RVQ ä¸ºè½»é‡çº§å®ç°
from vector_quantize_pytorch import ResidualVQ
# from NanoporeEncoder import NanoporeEncoder  # ğŸ‘ˆ æ·»åŠ è¿™ä¸€è¡Œ


# train_nanopore_rvq.py
# æœ¬è„šæœ¬ç›®æ ‡ï¼šè®­ç»ƒä¸€ä¸ªè‡ªç›‘ç£æ¨¡å‹ï¼Œå°† Nanopore åŸå§‹ç”µæµä¿¡å·ï¼ˆ5kHzï¼‰è½¬æ¢ä¸ºç¦»æ•£ token åºåˆ—ï¼Œ
# ç”¨äºåç»­è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPTï¼‰å»ºæ¨¡ DNA/RNA åºåˆ—ã€‚
# æ‰€æœ‰æ³¨é‡Šå‡ä¸ºå·¥ä¸šçº§è¯¦ç»†è¯´æ˜ï¼Œé€‚åˆ PyTorch æ–°æ‰‹ç†è§£ã€‚

import os
import torch                     # PyTorch ä¸»åº“ï¼Œç”¨äºå¼ é‡è®¡ç®—å’Œæ·±åº¦å­¦ä¹ 
import torch.nn as nn            # ç¥ç»ç½‘ç»œæ¨¡å—ï¼ˆå¦‚ Conv1d, BatchNorm, SiLUï¼‰
import torch.nn.functional as F  # å‡½æ•°å¼æ¥å£ï¼ˆå¦‚ loss, paddingï¼‰
from torch.utils.data import Dataset, DataLoader  # æ•°æ®åŠ è½½å·¥å…·
import numpy as np               # æ•°å€¼è®¡ç®—ï¼ˆç”Ÿæˆæ¨¡æ‹Ÿä¿¡å·ï¼‰
from tqdm import tqdm            # è¿›åº¦æ¡æ˜¾ç¤º

# æ›¿æ¢ encodec RVQ ä¸ºè½»é‡çº§å®ç°
from vector_quantize_pytorch import ResidualVQ

import torch.multiprocessing as mp
mp.set_start_method('spawn', force=True)  # ğŸ‘ˆ å¿…é¡»æ”¾åœ¨æœ€å¼€å¤´ï¼

# ----------------------------
# 2. Nanopore ä¸“ç”¨ç¼–ç å™¨ï¼ˆä¸¥æ ¼æŒ‰ä½ æä¾›çš„é…ç½®ï¼‰
# ----------------------------
class NanoporeEncoder(nn.Module):
    """
    å°†åŸå§‹ä¿¡å· [B, 1, T] ç¼–ç ä¸ºé«˜ç»´æ½œåœ¨è¡¨ç¤º [B, 512, T//12]
    ç»“æ„å®Œå…¨æŒ‰ç…§ä½ æä¾›çš„ YAML é…ç½®å®ç°ã€‚
    """
    def __init__(self):
        super().__init__()  # å¿…é¡»è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        layers = []  # ç”¨æ¥å­˜æ”¾æ‰€æœ‰ç½‘ç»œå±‚

        # Layer 1: å·ç§¯å±‚
        layers.append(nn.Conv1d(1, 64, kernel_size=5, stride=1, padding=2, bias=True))
        layers.append(nn.SiLU())
        layers.append(nn.BatchNorm1d(64))

        # Layer 2
        layers.append(nn.Conv1d(64, 64, kernel_size=5, stride=1, padding=2, bias=True))
        layers.append(nn.SiLU())
        layers.append(nn.BatchNorm1d(64))

        # Layer 3: ä¸‹é‡‡æ · stride=3
        layers.append(nn.Conv1d(64, 128, kernel_size=9, stride=3, padding=4, bias=True))
        layers.append(nn.SiLU())
        layers.append(nn.BatchNorm1d(128))

        # Layer 4: stride=2
        layers.append(nn.Conv1d(128, 128, kernel_size=9, stride=2, padding=4, bias=True))
        layers.append(nn.SiLU())
        layers.append(nn.BatchNorm1d(128))

        # Layer 5: stride=2
        layers.append(nn.Conv1d(128, 512, kernel_size=5, stride=2, padding=2, bias=True))
        layers.append(nn.SiLU())
        layers.append(nn.BatchNorm1d(512))

        self.net = nn.Sequential(*layers)
        self.total_stride = 1 * 1 * 3 * 2 * 2  # = 12

    def forward(self, x):
        z = self.net(x)
        return z



# train_nanopore_rvq.py
# æœ¬è„šæœ¬ç›®æ ‡ï¼šè®­ç»ƒä¸€ä¸ªè‡ªç›‘ç£æ¨¡å‹ï¼Œå°† Nanopore åŸå§‹ç”µæµä¿¡å·ï¼ˆ5kHzï¼‰è½¬æ¢ä¸ºç¦»æ•£ token åºåˆ—ï¼Œ
# ç”¨äºåç»­è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPTï¼‰å»ºæ¨¡ DNA/RNA åºåˆ—ã€‚
# æ‰€æœ‰æ³¨é‡Šå‡ä¸ºå·¥ä¸šçº§è¯¦ç»†è¯´æ˜ï¼Œé€‚åˆ PyTorch æ–°æ‰‹ç†è§£ã€‚

import os
import torch                     # PyTorch ä¸»åº“ï¼Œç”¨äºå¼ é‡è®¡ç®—å’Œæ·±åº¦å­¦ä¹ 
import torch.nn as nn            # ç¥ç»ç½‘ç»œæ¨¡å—ï¼ˆå¦‚ Conv1d, BatchNorm, SiLUï¼‰
import torch.nn.functional as F  # å‡½æ•°å¼æ¥å£ï¼ˆå¦‚ loss, paddingï¼‰
from torch.utils.data import Dataset, DataLoader  # æ•°æ®åŠ è½½å·¥å…·
import numpy as np               # æ•°å€¼è®¡ç®—ï¼ˆç”Ÿæˆæ¨¡æ‹Ÿä¿¡å·ï¼‰
from tqdm import tqdm            # è¿›åº¦æ¡æ˜¾ç¤º

# æ›¿æ¢ encodec RVQ ä¸ºè½»é‡çº§å®ç°
from vector_quantize_pytorch import ResidualVQ


# ----------------------------
# 3. å®Œæ•´ Tokenizer æ¨¡å‹ï¼ˆEncoder + RVQ + Decoderï¼‰
# ----------------------------
class NanoporeRVQModel(nn.Module):
    """
    å®Œæ•´çš„è‡ªç¼–ç å™¨ç»“æ„ï¼š
    - Encoder: å‹ç¼©ä¿¡å·
    - RVQ: å°†è¿ç»­ latent ç¦»æ•£åŒ–ä¸º tokens
    - Decoder: ä» tokens é‡å»ºåŸå§‹ä¿¡å·ï¼ˆç”¨äºè‡ªç›‘ç£è®­ç»ƒï¼‰
    """
    def __init__(self, n_q=4, codebook_size=1024):
        super().__init__()
        self.encoder = NanoporeEncoder()
        dim = 512

        # ä½¿ç”¨ vector_quantize_pytorch çš„ ResidualVQ
        self.rvq = ResidualVQ(
            num_quantizers=n_q,
            dim=dim,
            codebook_size=codebook_size,
            kmeans_init=True,           # æ›´ç¨³å®šè®­ç»ƒ
            kmeans_iters=10,
            threshold_ema_dead_code=2   # é˜²æ­¢ç æœ¬æ­»äº¡
        )

        # è§£ç å™¨ï¼šä¸Šé‡‡æ · Ã—12
        self.decoder = nn.Sequential(
            nn.ConvTranspose1d(dim, 256, kernel_size=8, stride=2, padding=3),
            nn.SiLU(),
            nn.BatchNorm1d(256),

            nn.ConvTranspose1d(256, 128, kernel_size=12, stride=2, padding=5),
            nn.SiLU(),
            nn.BatchNorm1d(128),

            nn.ConvTranspose1d(128, 64, kernel_size=18, stride=3, padding=8),
            nn.SiLU(),
            nn.BatchNorm1d(64),

            nn.Conv1d(64, 1, kernel_size=1),
        )
        self.total_stride = self.encoder.total_stride


    def forward(self, x):
        z = self.encoder(x)  # [B, 512, T_enc]  e.g., [B, 512, 1000]

        # è½¬ç½®ä¸º [B, T_enc, 512] â€”â€” ç¬¦åˆ vector_quantize_pytorch çš„è¦æ±‚
        z_transposed = z.permute(0, 2, 1)  # [B, T_enc, D]

        # ResidualVQ expects [B, T, D]
        z_q_transposed, indices, _ = self.rvq(z_transposed)

        # è½¬å› [B, D, T_enc] ç”¨äº decoder
        z_q = z_q_transposed.permute(0, 2, 1)  # [B, 512, T_enc]

        recon = self.decoder(z_q)  # [B, 1, T_rec]

        # å¯¹é½é•¿åº¦
        if recon.shape[2] > x.shape[2]:
            recon = recon[:, :, :x.shape[2]]
        elif recon.shape[2] < x.shape[2]:
            pad = x.shape[2] - recon.shape[2]
            recon = F.pad(recon, (0, pad))

        # indices is [B, T_enc, n_q] â€”â€” è¿™æ˜¯åˆç†çš„
        return recon, indices


class RVQTokenizer:
    """
    Nanopore RVQ Tokenizer å°è£…ç±»ã€‚

    åŠŸèƒ½ï¼š
        - åŠ è½½é¢„è®­ç»ƒ RVQ æ¨¡å‹
        - tokenize å•ä¸ª read / numpy ä¿¡å· / æ•´ä¸ª FAST5 ç›®å½•
    """

    def __init__(
        self,
        model_ckpt: str = "nanopore_rvq_tokenizer.pth",
        device: str = "cuda",
        cutoff: int = 1200,
        filter_order: int = 6,
        default_fs: int = 5000,
        chunk_size: int = 12000,
        stride: int = 11880,  # ğŸ‘ˆ æ›¿ä»£åŸæ¥çš„ stride_factorï¼Œä¾‹å¦‚ 12000 * 0.98 = 11760
        discard_feature: int = 5,
        downsample_rate: int = 12,
        token_type:str = "L4"
    ):
        """
        åˆå§‹åŒ– tokenizerã€‚

        Args:
            model_ckpt (str): RVQ æ¨¡å‹ checkpoint è·¯å¾„ã€‚
            device (str): æ¨ç†è®¾å¤‡ ('cuda' or 'cpu')ã€‚
            cutoff (int): æ»¤æ³¢æˆªæ­¢é¢‘ç‡ (Hz)ã€‚
            filter_order (int): Butterworth æ»¤æ³¢å™¨é˜¶æ•°ã€‚
            default_fs (int): é»˜è®¤é‡‡æ ·ç‡ (Hz)ï¼Œå½“ read æ—  metadata æ—¶ä½¿ç”¨ã€‚
            chunk_size (int): æ¨¡å‹è¾“å…¥ chunk é•¿åº¦ï¼ˆå¿…é¡»ä¸è®­ç»ƒä¸€è‡´ï¼Œå¦‚ 12000ï¼‰ã€‚
            stride (int): æ»‘åŠ¨çª—å£æ­¥é•¿ï¼ˆå•ä½ï¼šä¿¡å·ç‚¹ï¼‰ï¼Œç”¨äºé•¿ read åˆ†å—ã€‚å…¸å‹å€¼ = chunk_size - 2*discard_signalã€‚
            discard_feature (int): æ¯ç«¯ä¸¢å¼ƒçš„ token æ•°ï¼ˆå¯¹åº” 5 * 12 = 60 ä¿¡å·ç‚¹ï¼‰ã€‚
            downsample_rate (int): RVQ ä¸‹é‡‡æ ·ç‡ï¼ˆé€šå¸¸ä¸º 12ï¼‰ã€‚
        """
        self.device = device
        self.cutoff = cutoff
        self.filter_order = filter_order
        self.default_fs = default_fs
        self.chunk_size = chunk_size
        self.stride = stride  # ğŸ‘ˆ ç›´æ¥ä½¿ç”¨æ•´æ•° stride
        self.discard_feature = discard_feature
        self.downsample_rate = downsample_rate
        self.discard_signal = discard_feature * downsample_rate  # e.g., 60

        # Load model
        self.model_ckpt_path = model_ckpt  # ğŸ‘ˆ å¿…é¡»åŠ è¿™è¡Œï¼
        self.model = self._load_model(model_ckpt)
        self.n_q = self.model.rvq.num_quantizers  # e.g., 4
    def _load_model(self, ckpt_path):
        model = NanoporeRVQModel(n_q=4, codebook_size=8192)
        state_dict = torch.load(ckpt_path, map_location=self.device)
        model.load_state_dict(state_dict)
        model.eval()
        model.to(self.device)
        return model

    def _tokenize_chunked_signal(self, signal: np.ndarray) -> np.ndarray:
        """
        å¯¹ä»»æ„é•¿åº¦ä¿¡å·è¿›è¡Œåˆ†å— tokenizeï¼ˆå¸¦ discard è¾¹ç•Œï¼‰ï¼Œè¿”å›æ‰å¹³ token arrayã€‚
        å†…éƒ¨å¤„ç† padding / overlap / discardã€‚
        """
        if signal.ndim != 1:
            raise ValueError("Signal must be 1D.")
        L = len(signal)
        if L == 0:
            T_expected = (L + self.downsample_rate - 1) // self.downsample_rate
            return np.zeros(T_expected * self.n_q, dtype=np.int64)

        if L < self.chunk_size:
            padded = np.pad(signal, (0, self.chunk_size - L), mode='constant')
            x = torch.from_numpy(padded).float().unsqueeze(0).unsqueeze(0).to(self.device)
            with torch.no_grad():
                _, tokens = self.model(x)
            tokens = tokens.squeeze(0).cpu().numpy()  # [T_full, n_q]

            start_sig = self.discard_signal
            end_sig = L - self.discard_signal
            if start_sig >= end_sig:
                T_expected = (L + self.downsample_rate - 1) // self.downsample_rate
                return np.zeros(T_expected * self.n_q, dtype=np.int64)

            start_tok = int(np.ceil(start_sig / self.downsample_rate))
            end_tok = int(np.floor(end_sig / self.downsample_rate))
            end_tok = min(end_tok, tokens.shape[0])

            if start_tok >= end_tok:
                T_expected = (L + self.downsample_rate - 1) // self.downsample_rate
                return np.zeros(T_expected * self.n_q, dtype=np.int64)

            safe_tokens = tokens[start_tok:end_tok]
            return safe_tokens.flatten()

        # Long signal: sliding window
        all_tokens = []
        start = 0
        while start < L:
            end = start + self.chunk_size
            if end > L:
                chunk = np.pad(signal[start:], (0, end - L), mode='constant')
            else:
                chunk = signal[start:end]

            x = torch.from_numpy(chunk).float().unsqueeze(0).unsqueeze(0).to(self.device)
            with torch.no_grad():
                _, tokens = self.model(x)
            tokens = tokens.squeeze(0).cpu().numpy()  # [1000, n_q]

            if start == 0:
                keep = tokens[:-self.discard_feature] if self.discard_feature > 0 else tokens
            elif end >= L:
                keep = tokens[self.discard_feature:] if self.discard_feature > 0 else tokens
            else:
                keep = tokens[self.discard_feature:-self.discard_feature] if self.discard_feature > 0 else tokens

            all_tokens.append(keep)
            start += (self.chunk_size - 2 * self.discard_signal)  # overlap by 2*discard_signal

        if not all_tokens:
            T_expected = (L + self.downsample_rate - 1) // self.downsample_rate
            return np.zeros(T_expected * self.n_q, dtype=np.int64)

        final_tokens = np.concatenate(all_tokens, axis=0)
        T_expected = (L + self.downsample_rate - 1) // self.downsample_rate
        if final_tokens.shape[0] > T_expected:
            final_tokens = final_tokens[:T_expected]
        elif final_tokens.shape[0] < T_expected:
            pad = np.zeros((T_expected - final_tokens.shape[0], self.n_q), dtype=np.int64)
            final_tokens = np.concatenate([final_tokens, pad], axis=0)
        # [L1_t0, L2_t0, L3_t0, L4_t0, L1_t1, L2_t1, L3_t1, L4_t1, ...]
        return final_tokens.flatten()

    def tokenize_data(self, signal: np.ndarray, fs: int = None, token_type: str = "L4") -> str:
        """
        å¯¹åŸå§‹æµ®ç‚¹ä¿¡å·è¿›è¡Œ normalize + filter + tokenizeï¼Œå¹¶æŒ‰ token_type è¿”å›æ ¼å¼åŒ–å­—ç¬¦ä¸²ã€‚

        Args:
            signal (np.ndarray): 1D æµ®ç‚¹ä¿¡å·ï¼ˆscaledï¼Œå•ä½ pAï¼‰
            fs (int): é‡‡æ ·ç‡ï¼ˆHzï¼‰ï¼Œè‹¥ä¸º None åˆ™ç”¨ default_fs
            token_type (str): "L1", "L2", "L3", or "L4"ï¼ˆé»˜è®¤ "L4"ï¼‰

        Returns:
            str: æ ¼å¼å¦‚ "<|bwav:L1_123|><|bwav:L2_456|>..."
        """
        layer_map = {"L1": 1, "L2": 2, "L3": 3, "L4": 4}
        if token_type not in layer_map:
            raise ValueError(f"token_type must be one of {list(layer_map.keys())}, got {token_type}")
        n_layers = layer_map[token_type]

        if fs is None:
            fs = self.default_fs

        # Normalize
        norm_sig = nanopore_normalize(signal)
        if norm_sig.size == 0:
            return ""
        
        # åŸå§‹ä¿¡å·: raw_signal (é‡‡æ ·ç‡ 5000 Hz)
        # å…¸å‹ k-mer æŒç»­æ—¶é—´ â‰ˆ 2â€“5 ms â†’ å¯¹åº” 10â€“25 ä¸ªé‡‡æ ·ç‚¹

        # æ¨èçª—å£å¤§å°ï¼š3 ~ 7ï¼ˆå¥‡æ•°ï¼‰
        med_signal = medfilt(norm_sig, kernel_size=5)

        # Filter
        filtered = nanopore_filter(med_signal, fs=fs, cutoff=self.cutoff, order=self.filter_order)
        if filtered.size == 0 or np.isnan(filtered).any():
            return ""

        # Get flat token array from original method (unchanged)
        flat_tokens = self._tokenize_chunked_signal(filtered)  # shape: (T * 4,)
        if flat_tokens.size == 0:
            return ""

        # Reshape to (T, 4)
        if flat_tokens.size % self.n_q != 0:
            # Should not happen, but safe guard
            T = flat_tokens.size // self.n_q
            flat_tokens = flat_tokens[:T * self.n_q]
        tokens_2d = flat_tokens.reshape(-1, self.n_q)  # (T, 4)

        # Keep only first n_layers columns
        selected = tokens_2d[:, :n_layers]  # (T, n_layers)

        # Build formatted string
        parts = []
        for t in range(selected.shape[0]):
            for q in range(n_layers):
                token_id = int(selected[t, q])
                parts.append(f"<|bwav:L{q+1}_{token_id}|>")
        return "".join(parts)


    def tokenize_read(self, read, token_type: str = "L4") -> str:
        """
        ç›´æ¥ tokenize ä¸€ä¸ª ont_fast5_api read å¯¹è±¡ï¼Œè¿”å›æ ¼å¼åŒ– token å­—ç¬¦ä¸²ã€‚

        Args:
            read: fast5 read object
            token_type: "L1", "L2", "L3", or "L4"

        Returns:
            str: formatted token string
        """
        # --- Scale ---
        channel_info = read.handle[read.global_key + 'channel_id'].attrs
        offset = int(channel_info['offset'])
        scaling = channel_info['range'] / channel_info['digitisation']
        raw = read.handle[read.raw_dataset_name][:]
        scaled = np.array(scaling * (raw + offset), dtype=np.float32)

        # --- Get fs ---
        try:
            fs = int(channel_info['sampling_rate'])
        except KeyError:
            fs = self.default_fs

        return self.tokenize_data(scaled, fs=fs, token_type=token_type)


    def tokenize_fast5_file(self, fast5_path: str, output_path: str):
        print(f"âœ… Process {fast5_path}")
        """å†…éƒ¨æ–¹æ³•ï¼šå¤„ç†å•ä¸ª FAST5 â†’ JSONL.GZ"""
        results = []
        with get_fast5_file(fast5_path, mode="r") as f5:
            for read in tqdm(f5.get_reads()):
                try:
                    token_str = self.tokenize_read(read)
    
                    results.append({
                        "id": read.read_id,
                        "text": token_str
                    })
                except Exception as e:
                    print(f"âŒ Error on read {read.read_id} in {fast5_path}: {e}")
                    continue
    
        # Save
        with gzip.open(output_path, 'wt', encoding='utf-8') as f:
            for item in results:
                f.write(json.dumps(item) + '\n')
        print(f"âœ… Wrote {len(results)} reads to {output_path}")





